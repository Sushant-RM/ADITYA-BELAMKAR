<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Problems in Nature and Problem-Solving Paradigms</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <header>
        <h1>Problems in Nature and Problem-Solving Paradigms</h1>
        <p>Exploring algorithms and their connection to natural processes</p>
    </header>
    <main>
        <section>
            <h2>Iteration</h2>
            <p>Often seen in repetitive processes like counting waves, seasons, or cycles in nature. Iteration repeats a set of actions to achieve a result.</p>
            <ul>
                <li><strong>Counting:</strong> Iterating through days, hours, or seasons.</li>
                <li><strong>Growth Models:</strong> Iteratively calculating population growth in biology.</li>
            </ul>
        </section>

        <section>
            <h2>Recursion</h2>
            <p>This mirrors self-repeating patterns, like fractals in snowflakes or the Fibonacci sequence in flower petal arrangements. A problem is solved by breaking it into smaller, identical sub-problems.</p>
            <ul>
                <li><strong>Fractals:</strong> Natural objects like ferns or snowflakes exhibit recursive patterns.</li>
                <li><strong>Divide-and-Conquer:</strong> Splitting a large structure into smaller, manageable parts, similar to how rivers branch into tributaries.</li>
            </ul>
        </section>

        <section>
            <h2>Backtracking</h2>
            <p>Seen in decision-making scenarios in nature, like ants finding the shortest path to food. This approach involves exploring all possibilities and backtracking when a solution isn’t found.</p>
            <ul>
                <li><strong>Maze-Like Problems:</strong> How animals explore caves or burrows for food or shelter.</li>
                <li><strong>Game-Like Scenarios:</strong> Birds exploring multiple routes to nesting sites.</li>
            </ul>
        </section>

        <section>
            <h2>Space and Time Efficiency</h2>
            <h3>Definitions</h3>
            <ul>
                <li><strong>Time Efficiency:</strong> Measures how quickly an algorithm runs as input size grows.</li>
                <li><strong>Space Efficiency:</strong> Measures the amount of memory required to run an algorithm.</li>
            </ul>
            <h3>Importance</h3>
            <p>In a world with vast data, efficient algorithms save time and resources. For example, navigating a GPS route or processing social media feeds demands both.</p>
            <h3>Class of Problems</h3>
            <ul>
                <li><strong>P (Polynomial Time):</strong> Solvable efficiently. Example: Sorting a list, finding shortest paths.</li>
                <li><strong>NP (Nondeterministic Polynomial Time):</strong> Harder to solve but solutions are easy to verify. Example: Solving Sudoku, the Traveling Salesman Problem.</li>
                <li><strong>NP-Hard/NP-Complete:</strong> Extremely complex, no known polynomial-time solutions. Example: Protein folding in biology.</li>
            </ul>
            <h3>Orders of Growth</h3>
            <ul>
                <li><strong>O(1):</strong> Constant time, fastest. Example: Accessing an array element.</li>
                <li><strong>O(log n):</strong> Logarithmic, efficient for large data. Example: Binary search.</li>
                <li><strong>O(n):</strong> Linear, reasonable for moderate data sizes. Example: Scanning a list.</li>
                <li><strong>O(n^2):</strong> Quadratic, slows significantly for larger data. Example: Bubble sort.</li>
                <li><strong>O(2^n):</strong> Exponential, infeasible for large inputs. Example: Recursive Fibonacci.</li>
            </ul>
        </section>

        <section>
            <h2>Takeaways from Design Principles</h2>
            <ul>
                <li><strong>Divide and Conquer:</strong> Break problems into smaller sub-problems, solve independently, then combine. Example: Merge Sort.</li>
                <li><strong>Dynamic Programming:</strong> Reuse solutions to overlapping sub-problems. Example: Fibonacci numbers.</li>
                <li><strong>Greedy Algorithms:</strong> Make locally optimal choices for a globally optimal solution. Example: Dijkstra’s algorithm.</li>
                <li><strong>Brute Force:</strong> Explore all possibilities. Simplistic but computationally expensive. Example: Generating all subsets.</li>
            </ul>
        </section>

        <section>
            <h2>Hierarchical Data and Tree Structures</h2>
            <p>Trees model hierarchical relationships like family trees, file systems, or organizational charts.</p>
            <h3>Types of Trees</h3>
            <ul>
                <li><strong>Binary Trees:</strong> Each node has at most two children.</li>
                <li><strong>Binary Search Trees (BSTs):</strong> Maintain sorted order for efficient searching.</li>
                <li><strong>AVL Trees:</strong> Self-balancing BST ensuring O(log n) operations.</li>
                <li><strong>Red-Black Trees:</strong> Similar to AVL, with less strict balancing rules.</li>
                <li><strong>2-3 Trees:</strong> Balanced multi-way trees used in databases.</li>
                <li><strong>Heaps:</strong> Specialized trees for priority queues.</li>
                <li><strong>Tries:</strong> Used for string operations like autocomplete.</li>
            </ul>
            <h3>Optimizations</h3>
            <ul>
                <li><strong>AVL Trees:</strong> Balance ensures fast search, insert, and delete.</li>
                <li><strong>Heaps:</strong> Efficient for retrieving minimum or maximum values.</li>
                <li><strong>Tries:</strong> Optimize prefix searches in dictionaries.</li>
            </ul>
        </section>

        <section>
            <h2>Array Query Algorithms</h2>
            <h3>Need</h3>
            <p>Arrays are foundational for storing sequential data. Querying arrays efficiently is critical for applications like:</p>
            <ul>
                <li>Finding ranges in data (e.g., sum or maximum in a subarray).</li>
                <li>Searching and filtering operations.</li>
            </ul>
            <h3>Applications</h3>
            <ul>
                <li><strong>Segment Trees:</strong> Efficient range queries.</li>
                <li><strong>Fenwick Trees:</strong> Efficient cumulative frequency calculations.</li>
            </ul>
            <h3>Principles</h3>
            <ul>
                <li><strong>Preprocessing:</strong> Prepare the array for quick queries (e.g., prefix sums).</li>
                <li><strong>Divide-and-Conquer:</strong> Split queries into manageable chunks.</li>
            </ul>
        </section>

        <section>
            <h2>Trees vs. Graphs and Their Traversals</h2>
            <h3>Differences Between Trees and Graphs</h3>
            <table>
                <thead>
                    <tr>
                        <th>Aspect</th>
                        <th>Trees</th>
                        <th>Graphs</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>Structure</td>
                        <td>Hierarchical and acyclic.</td>
                        <td>Can have cycles and no strict hierarchy.</td>
                    </tr>
                    <tr>
                        <td>Examples</td>
                        <td>File systems, organizational charts.</td>
                        <td>Road networks, social networks.</td>
                    </tr>
                    <tr>
                        <td>Traversals</td>
                        <td>Inorder, Preorder, Postorder.</td>
                        <td>BFS (Breadth-First Search), DFS (Depth-First Search).</td>
                    </tr>
                </tbody>
            </table>
            <h3>Applications</h3>
            <ul>
                <li><strong>Trees:</strong> File systems, organizational charts, expression parsing.</li>
                <li><strong>Graphs:</strong> GPS navigation, social network analysis, scheduling tasks.</li>
            </ul>
        </section>

        <section>
            <h2>Sorting and Searching Algorithms</h2>
            <h3>Sorting</h3>
            <p>Organizes data for efficiency.</p>
            <h4>Types</h4>
            <ul>
                <li><strong>Quick Sort:</strong> Divide-and-conquer, fast for average cases.</li>
                <li><strong>Merge Sort:</strong> Stable, divide-and-conquer.</li>
                <li><strong>Bubble Sort:</strong> Simplistic but inefficient.</li>
                <li><strong>Heap Sort:</strong> Uses heap data structure for sorting.</li>
            </ul>
            <h4>Real-World Connections</h4>
            <p>Ranking students, sorting emails.</p>
            <h3>Searching</h3>
            <p>Finding elements in datasets.</p>
            <h4>Types</h4>
            <ul>
                <li><strong>Linear Search:</strong> Check each element, simple but slow.</li>
                <li><strong>Binary Search:</strong> Fast, requires sorted data.</li>
            </ul>
            <h4>Real-World Connections</h4>
            <p>Looking up contact information, finding products in databases.</p>
        </section>

        <section>
            <h2>Importance of Graph Algorithms: Spanning Trees and Shortest Paths</h2>
            <h3>Spanning Trees</h3>
            <p>A spanning tree connects all nodes with the minimum number of edges.</p>
            <h4>Algorithms</h4>
            <ul>
                <li><strong>Kruskal's Algorithm:</strong> Builds a minimum spanning tree by sorting edges.</li>
                <li><strong>Prim's Algorithm:</strong> Grows the minimum spanning tree by selecting edges with the least weight.</li>
            </ul>
            <h3>Shortest Path</h3>
            <p>Finding the shortest path between two nodes in a graph is essential for routing.</p>
            <h4>Algorithms</h4>
            <ul>
                <li><strong>Dijkstra's Algorithm:</strong> Finds the shortest path in a graph with positive edge weights.</li>
                <li><strong>Bellman-Ford Algorithm:</strong> Handles negative edge weights.</li>
            </ul>
        </section>
    </main>
    <footer>
        <p>Designed by YourName</p>
    </footer>
</body>
</html>
